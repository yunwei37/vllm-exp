{
  "issue_type": "performance",
  "extracted_from": "/root/yunwei37/vllm-exp/bug-study/analysis_llm/sample_results/vllm/label_based/performance/issues.json",
  "issue": {
    "number": 9609,
    "title": "[Performance]: test speculative decode accuracy",
    "body": "### Proposal to improve performance\n\nI use lm-evaluation-harness to test vllm accuracy\r\n1.when don't enable spec decode,I got some result below\r\nnum_concurrent=1\r\n![image](https://github.com/user-attachments/assets/dfa6ef55-216e-4460-9ef4-d387e0ce460e)\r\n\r\nnum_concurrent=8\r\n![image](https://github.com/user-attachments/assets/505d051f-f119-4275-a5d4-5683b74be398)\r\n\r\nnum_concurrent=16\r\n![image](https://github.com/user-attachments/assets/87e7c9c6-f2de-43de-8a20-96f82c4c9c7c)\r\n\r\nnum_concurrent=32\r\n![image](https://github.com/user-attachments/assets/312e2703-cfc8-42c7-9751-22a0b1aba21d)\r\n\r\n\r\n2.when enable spec decode,I got some result below\r\nnum_concurrent=1\r\n![image](https://github.com/user-attachments/assets/6681a17f-3bc7-4d52-b0e5-5451a40dfcf4)\r\n\r\nnum_concurrent=8\r\n![image](https://github.com/user-attachments/assets/4a1878a8-2da7-475e-9ecd-8400a6fc0620)\r\n\r\nnum_concurrent=16\r\n![image](https://github.com/user-attachments/assets/fc9ca925-a57c-4c6f-9a07-1fa056e67d66)\r\n\r\nnum_concurrent=32\r\n![image](https://github.com/user-attachments/assets/67d284c2-9023-440c-88fa-f61c3f6090de)\r\n\r\nHas anyone done such experiments? Does vLLM's speculative decoding affect output accuracy?\r\n\n\n### Report of performance regression\n\n_No response_\n\n### Misc discussion on performance\n\n_No response_\n\n### Your current environment (if you think it is necessary)\n\nh100 1gpu\r\n\n\n### Before submitting a new issue...\n\n- [X] Make sure you already searched for relevant issues, and asked the chatbot living at the bottom right corner of the [documentation page](https://docs.vllm.ai/en/latest/), which can answer lots of frequently asked questions.",
    "labels": [
      "performance"
    ],
    "state": "closed",
    "created_at": "2024-10-23T07:40:46+00:00",
    "closed_at": "2024-10-25T09:18:03+00:00",
    "comments": 1,
    "reactions": {
      "url": "https://api.github.com/repos/vllm-project/vllm/issues/9609/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "author_association": "NONE",
    "html_url": "https://github.com/vllm-project/vllm/issues/9609"
  }
}