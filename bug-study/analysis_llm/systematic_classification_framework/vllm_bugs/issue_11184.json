{
  "issue_type": "bug",
  "extracted_from": "/root/yunwei37/vllm-exp/bug-study/analysis_llm/sample_results/vllm/label_based/bug/issues.json",
  "issue": {
    "number": 11184,
    "title": "[Bug]: Bert tokenizer is tokenizing some tokens as `UNK`",
    "body": "### Your current environment\n\n<details>\r\n<summary>The output of `python collect_env.py`</summary>\r\n\r\n```text\r\nYour output of `python collect_env.py` here\r\n```\r\n\r\n</details>\r\n\n\n### Model Input Dumps\n\n_No response_\n\n### \ud83d\udc1b Describe the bug\n\nWith some Bert and Roberta models like `sentence-transformers/all-MiniLM-L12-v2` I found that the output is not similar to the one generated by `sentence-transformers`. If I place the following prints in `_normalize_prompt_text_to_input()` in `serving_engine.py`\r\n```\r\n        print(f\"{input_ids=}\")\r\n```\r\nI get `[101, 100, 3007, 1997, 100, 2003, 100, 1012, 102]` for the sentence \"The capital of France is Paris.\". 100 is the `UNK` token.  When I run with sentence-transformers, I get `[ 101, 1996, 3007, 1997, 2605, 2003, 3000, 1012,  102]` . This problem happens both with `--tokenizer-mode auto` and `--tokenizer-mode slow`.\r\n\r\ncc: @DarkLight1337 \n\n### Before submitting a new issue...\n\n- [X] Make sure you already searched for relevant issues, and asked the chatbot living at the bottom right corner of the [documentation page](https://docs.vllm.ai/en/latest/), which can answer lots of frequently asked questions.",
    "labels": [
      "bug"
    ],
    "state": "closed",
    "created_at": "2024-12-13T21:33:18+00:00",
    "closed_at": "2025-01-09T03:05:45+00:00",
    "comments": 1,
    "reactions": {
      "url": "https://api.github.com/repos/vllm-project/vllm/issues/11184/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "author_association": "CONTRIBUTOR",
    "html_url": "https://github.com/vllm-project/vllm/issues/11184"
  }
}